{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/aaronwayne/miniconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train[0,:,:])\n",
    "\n",
    "# standardize\n",
    "new_x_train = x_train / 255\n",
    "\n",
    "print(new_x_train.shape)\n",
    "\n",
    "reshaped_x_train = np.reshape(new_x_train, (60000, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "\n",
    "reshaped_y_train = np.zeros((60000,10))\n",
    "for (i, value) in enumerate(y_train):\n",
    "    new_y_train[i, value] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights_1 = np.random.normal(size=(28*28, 128), scale=1/np.sqrt(28*28))\n",
    "# biases_1 = np.zeros((1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def sigmoid(z):\n",
    "#    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def pre_activations(X, W, b):\n",
    "#    return np.dot(X,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def activations(X, W, b):\n",
    "#    return sigmoid(pre_activations(X, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights_2 = np.random.normal(size=(128, 10), scale=1/np.sqrt(128))\n",
    "#biases_2 = np.zeros((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def soft_max(X, W, b):\n",
    "#    z = pre_activations(X, W, b)\n",
    "#    expz = np.exp(z)\n",
    "#    sums = np.sum(expz, axis=0)\n",
    "#    return expz / sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def forward_propogate(X):\n",
    "#    hidden_1 = activations(X, weights_1, biases_1)\n",
    "#    return soft_max(hidden_1, weights_2, biases_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "\n",
    "    def __init__(self, input_length, output_length):\n",
    "        self.in_len = input_length\n",
    "        self.out_len = output_length\n",
    "        self.weights = np.random.normal(\n",
    "            size=(self.in_len, self.out_len),\n",
    "            scale=1/np.sqrt(self.in_len))\n",
    "        self.biases = np.zeros((1, self.out_len))\n",
    "\n",
    "    def soft_max(self, X):\n",
    "        pre = self.pre_activations(X)\n",
    "        exp_pre = np.exp(pre)\n",
    "        sums = np.sum(exp_pre, axis=1).reshape((-1, 1))\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        #sums = np.dot(exp_pre, np.ones((10,1)))\n",
    "        return exp_pre / sums\n",
    "\n",
    "    def activations(self, X):\n",
    "        pre = self.pre_activations(X)\n",
    "        return self.__class__.sigmoid(pre)\n",
    "\n",
    "    def pre_activations(self, X):\n",
    "        return np.dot(X, self.weights) + self.biases\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.layers = []\n",
    "        self.size = size\n",
    "        # add line to reshape if it isn't correct\n",
    "\n",
    "    def add_layer(self, output_length):\n",
    "        num_layers = len(self.layers)\n",
    "        in_len = self.layers[num_layers - 1].out_len if num_layers > 0 else self.size\n",
    "        self.layers.append(DenseLayer(in_len, output_length))\n",
    "\n",
    "    def forward_propogate(self, x_train):\n",
    "        result = x_train\n",
    "        for (i, layer) in enumerate(self.layers):\n",
    "            if (i == len(self.layers) - 1):\n",
    "                return layer.soft_max(result)\n",
    "            else:\n",
    "                result = layer.activations(result)\n",
    "    \n",
    "    def calculate_errors(self, results, y_train):\n",
    "        error = -np.log(result)\n",
    "        return np.sum(error * y_train)\n",
    "\n",
    "    def accuracy(self, results, y_train):\n",
    "        predictions = np.argmax(results, axis=1)\n",
    "        correct_answers = np.argmax(y_train, axis=1)\n",
    "        return np.sum(predictions == correct_answers)\n",
    "\n",
    "    def derivative_of_sm_cross_entropy(self, hidden, y_train, predictions):\n",
    "        hidden_reshape = hidden.reshape((-1, hidden.shape[1], 1))\n",
    "        hidden_repeat = np.repeat(hidden_reshape, y_train.shape[1], axis = 2)\n",
    "        \n",
    "        cross_ent_deriv = predictions - y_train\n",
    "        cross_ent_deriv_reshape = cross_ent_deriv.reshape((-1, 1, y_train.shape[1]))\n",
    "        cross_ent_deriv_repeat = np.repeat(cross_ent_deriv_reshape, hidden.shape[1], axis=1)\n",
    "        return np.sum(hidden_repeat * cross_ent_deriv_repeat, axis=0)\n",
    "\n",
    "    def backprop(self, layer_inputs, hidden_output_values, ce_deriv_with_r_h):\n",
    "        # TODO: generalize for batches of inputs\n",
    "        num_outputs = 128\n",
    "        layer_inputs_reshape = layer_inputs.reshape((-1, 1))\n",
    "        layer_inputs_repeat = np.repeat(layer_inputs_reshape, num_outputs, axis=1)\n",
    "\n",
    "        deriv_h_with_r_z = hidden_output_values * (1 - hidden_output_values)\n",
    "\n",
    "        ce_deriv_ce_with_respect_to_z = (ce_deriv_with_r_h * deriv_h_with_r_z).reshape((1, -1))\n",
    "        return layer_inputs_repeat * ce_deriv_ce_with_respect_to_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10682457 0.12497473 0.05442231 ... 0.05517881 0.17525571 0.13171869]\n",
      " [0.10624418 0.12453039 0.05428742 ... 0.05507768 0.17608975 0.13129448]\n",
      " [0.10611709 0.12526361 0.05423544 ... 0.05473271 0.17616214 0.13172078]\n",
      " ...\n",
      " [0.10694583 0.12493339 0.05392322 ... 0.05508292 0.17515664 0.13183203]\n",
      " [0.10617037 0.12481319 0.05401659 ... 0.05519563 0.17494856 0.13116307]\n",
      " [0.10587407 0.12462835 0.05431938 ... 0.05498042 0.17520167 0.13194164]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "net = Network(reshaped_x_train, )\n",
    "net.add_layer(128)\n",
    "net.add_layer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,  63,  66,  69,  72],\n",
       "       [ 75,  78,  81,  84,  87],\n",
       "       [ 90,  93,  96,  99, 102],\n",
       "       [105, 108, 111, 114, 117]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.arange(60).reshape((3,4,5)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
