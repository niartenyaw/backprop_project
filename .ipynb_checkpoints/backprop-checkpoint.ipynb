{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/aaronwayne/miniconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train[0,:,:])\n",
    "\n",
    "# standardize\n",
    "new_x_train = x_train / 255\n",
    "\n",
    "print(new_x_train.shape)\n",
    "\n",
    "reshaped_x_train = np.reshape(new_x_train, (60000, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "\n",
    "new_y_train = np.zeros((60000,10))\n",
    "for (i, value) in enumerate(y_train):\n",
    "    new_y_train[i, value] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights_1 = np.random.normal(size=(28*28, 128), scale=1/np.sqrt(28*28))\n",
    "# biases_1 = np.zeros((1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def sigmoid(z):\n",
    "#    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def pre_activations(X, W, b):\n",
    "#    return np.dot(X,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def activations(X, W, b):\n",
    "#    return sigmoid(pre_activations(X, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights_2 = np.random.normal(size=(128, 10), scale=1/np.sqrt(128))\n",
    "#biases_2 = np.zeros((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def soft_max(X, W, b):\n",
    "#    z = pre_activations(X, W, b)\n",
    "#    expz = np.exp(z)\n",
    "#    sums = np.sum(expz, axis=0)\n",
    "#    return expz / sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def forward_propogate(X):\n",
    "#    hidden_1 = activations(X, weights_1, biases_1)\n",
    "#    return soft_max(hidden_1, weights_2, biases_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "\n",
    "    def __init__(self, input_length, output_length):\n",
    "        self.in_len = input_length\n",
    "        self.out_len = output_length\n",
    "        self.weights = np.random.normal(size=(self.in_len, self.out_len), scale=1/np.sqrt(self.out_len))\n",
    "        self.biases = np.zeros((1, self.out_len))\n",
    "\n",
    "    def soft_max(self, X):\n",
    "        pre = self.pre_activations(X)\n",
    "        exp_pre = np.exp(pre)\n",
    "        #sums = np.sum(exp_pre, axis=0)\n",
    "        sums = np.dot(exp_pre, np.ones((10,1)))\n",
    "        return exp_pre / sums\n",
    "\n",
    "    def activations(self, X):\n",
    "        pre = self.pre_activations(X)\n",
    "        return self.__class__.sigmoid(pre)\n",
    "\n",
    "    def pre_activations(self, X):\n",
    "        return np.dot(X, self.weights) + self.biases\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.layers = []\n",
    "        # add line to reshape if it isn't correct\n",
    "        self.data = data\n",
    "\n",
    "    def add_layer(self, output_length):\n",
    "        num_layers = len(self.layers)\n",
    "        in_len = self.layers[num_layers - 1].out_len if num_layers > 0 else self.data.shape[1]\n",
    "        self.layers.append(DenseLayer(in_len, output_length))\n",
    "\n",
    "    def forward_propogate(self):\n",
    "        result = self.data\n",
    "        for (i, layer) in enumerate(self.layers):\n",
    "            if (i == len(self.layers) - 1):\n",
    "                return layer.soft_max(result)\n",
    "            else:\n",
    "                result = layer.activations(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18669996 0.02264571 0.00171229 ... 0.05002698 0.19734373 0.04697053]\n",
      " [0.17686762 0.02369618 0.00174104 ... 0.04891883 0.2076648  0.0459914 ]\n",
      " [0.17575016 0.02204357 0.0017631  ... 0.04622285 0.19061613 0.04892695]\n",
      " ...\n",
      " [0.19783043 0.02355495 0.00169083 ... 0.05064176 0.19370544 0.0466007 ]\n",
      " [0.18917529 0.02327006 0.0017239  ... 0.04851646 0.19079796 0.04639608]\n",
      " [0.1824049  0.02238624 0.00170184 ... 0.04664266 0.1904163  0.04756369]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "net = Network(reshaped_x_train)\n",
    "net.add_layer(128)\n",
    "net.add_layer(128)\n",
    "net.add_layer(128)\n",
    "net.add_layer(10)\n",
    "print(net.forward_propogate())\n",
    "print(sum(net.forward_propogate()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
