{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlaceholderTensor:\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self._value = value\n",
    "        self.subsequent_tensor = None\n",
    "\n",
    "    def set_value(self, value):\n",
    "        self._value = value\n",
    "\n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "\n",
    "    def value(self):\n",
    "        return self._value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlusTensor:\n",
    "    \n",
    "    def __init__(self, previous, bias):\n",
    "        self.previous = previous\n",
    "        self.bias = bias\n",
    "        self.calculated_value = None\n",
    "        self.subsequent_tensor = None\n",
    "        self.previous.set_subsequent_tensor(self)\n",
    "        self.bias.set_subsequent_tensor(self)\n",
    "\n",
    "    \n",
    "    def deriv_error(self, input_tensor):\n",
    "        return self.subsequent_tensor.deriv_error(self)\n",
    "        \n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "    \n",
    "    def value(self):\n",
    "        if self.calculated_value is None:\n",
    "            self.calculated_value = self.previous.value() + self.bias.value()\n",
    "        return self.calculated_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiplyTensor:\n",
    "    \n",
    "    def __init__(self, vect, weight):\n",
    "        self.vect = vect\n",
    "        self.weight = weight\n",
    "        self.subsequent_tensor = None\n",
    "        self.error_vect = None\n",
    "        self.error_weight = None\n",
    "        self.vect.set_subsequent_tensor(self)\n",
    "        self.weight.set_subsequent_tensor(self)\n",
    "\n",
    "\n",
    "    \n",
    "    def deriv_error(self, input_tensor):\n",
    "        if input_tensor is self.vect:\n",
    "            return self.deriv_error_vect()\n",
    "        else:\n",
    "            return self.deriv_error_weight()\n",
    "\n",
    "    def deriv_error_vect(self):\n",
    "        if self.error_vect is None:\n",
    "            self.error_vect = np.dot(self.weight.value(), self.subsequent_tensor.deriv_error(self))\n",
    "        return self.error_vect\n",
    "    \n",
    "    def deriv_error_weight(self):\n",
    "        if self.error_weight is None:\n",
    "            self.error_weight = np.outer(self.vect.value(), self.subsequent_tensor.deriv_error(self))\n",
    "        return self.error_weight\n",
    "    \n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "    \n",
    "    def value(self):\n",
    "        return np.dot(self.vect.value(), self.weight.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftMaxCETensor:\n",
    "    \n",
    "    def __init__(self, preactivation_tensor, true_y_tensor):\n",
    "        self.preactivation_tensor = preactivation_tensor\n",
    "        self.true_y_tensor = true_y_tensor # assume one-hot encoding\n",
    "        self.calculated_h_values = None\n",
    "        self.gradient = None\n",
    "        self.log_loss = None\n",
    "        self.preactivation_tensor.set_subsequent_tensor(self)\n",
    "    \n",
    "    def deriv_error(self, input_tensor):\n",
    "        if self.gradient is None:\n",
    "            self.gradient = self.h_value() - self.true_y_tensor.value()\n",
    "        return self.gradient\n",
    "\n",
    "    def h_value(self):\n",
    "        if self.calculated_h_values is None:\n",
    "            pre_e = np.exp(self.preactivation_tensor.value())\n",
    "            sums = np.sum(pre_e)\n",
    "            self.calculated_h_values = pre_e / sums\n",
    "        return self.calculated_h_values\n",
    "    \n",
    "    def value(self):\n",
    "        if self.log_loss is None:\n",
    "            y_star_prob = np.sum(np.multiply(self.h_value(), self.true_y_tensor.value()))\n",
    "            self.log_loss = -np.log(y_star_prob)\n",
    "        return self.log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidTensor:\n",
    "    \n",
    "    def __init__(self, pre_activations):\n",
    "        self.pre_activations = pre_activations\n",
    "        self.activations = None\n",
    "        self.gradient = None\n",
    "        self.subsequent_tensor = None\n",
    "        \n",
    "    def deriv_error(self, input_tensor):\n",
    "        if self.gradient is None:\n",
    "            self.gradient = np.multiply(self.value(), (1 - self.value()))\n",
    "        return self.gradient\n",
    "\n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "    \n",
    "    def value(self):\n",
    "        if self.activations is None:\n",
    "            pre_exp = np.exp(self.pre_activations)\n",
    "            self.activations = pre_exp / (1 + pre_exp)\n",
    "        return self.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PlaceholderTensor' object has no attribute 'set_subsequent_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7ece28de3deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholderTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiplyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholderTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-bcb8f5d00764>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vect, weight)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_subsequent_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_subsequent_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PlaceholderTensor' object has no attribute 'set_subsequent_tensor'"
     ]
    }
   ],
   "source": [
    "x = PlaceholderTensor(np.array([1, 2, 3, 4]))\n",
    "y = PlaceholderTensor(np.array([0, 1]))\n",
    "\n",
    "weight = PlaceholderTensor(np.random.uniform(size=(4, 2)))\n",
    "mult = MultiplyTensor(x, weight)\n",
    "\n",
    "bias = PlaceholderTensor(np.zeros(shape=(2,)))\n",
    "plus = PlusTensor(mult, bias)\n",
    "\n",
    "soft_max = SoftMaxCETensor(plus, y)\n",
    "\n",
    "print(soft_max.value())\n",
    "print(soft_max.deriv_error(plus))\n",
    "print(plus.deriv_error(mult))\n",
    "print(mult.deriv_error(weight))\n",
    "print(mult.deriv_error(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
