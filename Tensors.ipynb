{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlaceholderTensor:\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self._value = value\n",
    "        self.subsequent_tensor = None\n",
    "\n",
    "    def set_value(self, value):\n",
    "        self._value = value\n",
    "\n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "\n",
    "    def value(self):\n",
    "        return self._value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlusTensor:\n",
    "    \n",
    "    def __init__(self, previous, bias):\n",
    "        self.previous = previous\n",
    "        self.bias = bias\n",
    "        self.calculated_value = None\n",
    "        self.subsequent_tensor = None\n",
    "        self.previous.set_subsequent_tensor(self)\n",
    "        self.bias.set_subsequent_tensor(self)\n",
    "\n",
    "    \n",
    "    def deriv_error(self, input_tensor):\n",
    "        return self.subsequent_tensor.deriv_error(self)\n",
    "        \n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "    \n",
    "    def value(self):\n",
    "        if self.calculated_value is None:\n",
    "            self.calculated_value = self.previous.value() + self.bias.value()\n",
    "        return self.calculated_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiplyTensor:\n",
    "    \n",
    "    def __init__(self, vect, weight):\n",
    "        self.vect = vect\n",
    "        self.weight = weight\n",
    "        self.subsequent_tensor = None\n",
    "        self.error_vect = None\n",
    "        self.error_weight = None\n",
    "        self.vect.set_subsequent_tensor(self)\n",
    "        self.weight.set_subsequent_tensor(self)\n",
    "\n",
    "\n",
    "    \n",
    "    def deriv_error(self, input_tensor):\n",
    "        if input_tensor is self.vect:\n",
    "            return self.deriv_error_vect()\n",
    "        elif input_tensor is self.weight:\n",
    "            return self.deriv_error_weight()\n",
    "        else:\n",
    "            raise \"incorrect tensor given\"\n",
    "\n",
    "    def deriv_error_vect(self):\n",
    "        if self.error_vect is None:\n",
    "            self.error_vect = np.dot(self.weight.value(), self.subsequent_tensor.deriv_error(self))\n",
    "        return self.error_vect\n",
    "    \n",
    "    def deriv_error_weight(self):\n",
    "        if self.error_weight is None:\n",
    "            self.error_weight = np.outer(self.vect.value(), self.subsequent_tensor.deriv_error(self))\n",
    "        return self.error_weight\n",
    "    \n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "    \n",
    "    def value(self):\n",
    "        return np.dot(self.vect.value(), self.weight.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftMaxCETensor:\n",
    "    \n",
    "    def __init__(self, preactivation_tensor, true_y_tensor):\n",
    "        self.preactivation_tensor = preactivation_tensor\n",
    "        self.true_y_tensor = true_y_tensor # assume one-hot encoding\n",
    "        self.calculated_h_values = None\n",
    "        self.gradient = None\n",
    "        self.log_loss = None\n",
    "        self.preactivation_tensor.set_subsequent_tensor(self)\n",
    "    \n",
    "    def deriv_error(self, input_tensor):\n",
    "        if self.gradient is None:\n",
    "            self.gradient = self.h_value() - self.true_y_tensor.value()\n",
    "        return self.gradient\n",
    "\n",
    "    def h_value(self):\n",
    "        if self.calculated_h_values is None:\n",
    "            pre_e = np.exp(self.preactivation_tensor.value())\n",
    "            sums = np.sum(pre_e)\n",
    "            self.calculated_h_values = pre_e / sums\n",
    "        return self.calculated_h_values\n",
    "    \n",
    "    def value(self):\n",
    "        if self.log_loss is None:\n",
    "            y_star_prob = np.sum(np.multiply(self.h_value(), self.true_y_tensor.value()))\n",
    "            self.log_loss = -np.log(y_star_prob)\n",
    "        return self.log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidTensor:\n",
    "    \n",
    "    def __init__(self, pre_activations):\n",
    "        self.pre_activations = pre_activations\n",
    "        self.activations = None\n",
    "        self.gradient = None\n",
    "        self.subsequent_tensor = None\n",
    "        \n",
    "    def deriv_error(self, input_tensor):\n",
    "        if self.gradient is None:\n",
    "            self.gradient = np.multiply(self.value(), (1 - self.value()))\n",
    "        return self.gradient\n",
    "\n",
    "    def set_subsequent_tensor(self, tensor):\n",
    "        self.subsequent_tensor = tensor\n",
    "    \n",
    "    def value(self):\n",
    "        if self.activations is None:\n",
    "            pre_exp = np.exp(self.pre_activations)\n",
    "            self.activations = pre_exp / (1 + pre_exp)\n",
    "        return self.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19320874586573267\n",
      "[ 0.17569012 -0.17569012]\n",
      "[ 0.17569012 -0.17569012]\n",
      "[[ 0.17569012 -0.17569012]\n",
      " [ 0.35138023 -0.35138023]\n",
      " [ 0.52707035 -0.52707035]\n",
      " [ 0.70276046 -0.70276046]]\n",
      "[-0.03524979  0.08523946 -0.07560523 -0.04499989]\n"
     ]
    }
   ],
   "source": [
    "x = PlaceholderTensor(np.array([1, 2, 3, 4]))\n",
    "y = PlaceholderTensor(np.array([0, 1]))\n",
    "\n",
    "weight = PlaceholderTensor(np.random.uniform(size=(4, 2)))\n",
    "mult = MultiplyTensor(x, weight)\n",
    "\n",
    "bias = PlaceholderTensor(np.zeros(shape=(2,)))\n",
    "plus = PlusTensor(mult, bias)\n",
    "\n",
    "soft_max = SoftMaxCETensor(plus, y)\n",
    "\n",
    "print(soft_max.value())\n",
    "print(soft_max.deriv_error(plus))\n",
    "print(plus.deriv_error(bias))\n",
    "print(mult.deriv_error(weight))\n",
    "print(mult.deriv_error(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
